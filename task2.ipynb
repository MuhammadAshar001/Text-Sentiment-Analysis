{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e99cd737-da08-44ea-a25b-8924d702de21",
   "metadata": {},
   "source": [
    "# IMDB Reviews Text Sentiment Analysis\n",
    "\n",
    "This project performs **sentiment analysis** on a dataset of text data to classify it as either positive or negative. Sentiment analysis is a natural language processing (NLP) technique used to determine whether textual data expresses a positive or negative sentiment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ea73650-654a-4778-9d93-f5095ade0661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6e2167d-cc1b-4fb6-bc85-2591ac3bb1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset using pandas\n",
    "ds = pd.read_csv('IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3cda6f9-8b9a-4c89-823d-0e12b70704a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a996615-96b5-4b62-aff1-c6e3e42f6830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eff1fafd-172c-4c7e-aa11-d9bf9b82cc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding out how many positive and negative sentiments\n",
    "ds['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c564394c-a1dc-4722-8233-a1a5716fdb2b",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "Text data is cleaned by:\n",
    "- Converting to lowercase\n",
    "- Removing punctuation, stopwords, and non-alphabetic characters\n",
    "- Tokenizing and lemmatizing words  \n",
    "This prepares the text for consistent and efficient machine learning analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85102f8f-002c-4f64-93e3-a2e7fa444eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\PMLS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\PMLS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\PMLS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b40c6759-f1c5-4105-a176-9aa3268cfbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_nltk(text):\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "\n",
    "    # Tokenize text\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords and lemmatize\n",
    "    cleaned_words = [\n",
    "        lemmatizer.lemmatize(word)\n",
    "        for word in words\n",
    "        if word.isalpha() and word not in stop_words\n",
    "    ]\n",
    "\n",
    "    return \" \".join(cleaned_words)\n",
    "\n",
    "ds['review'] = ds['review'].apply(preprocess_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fceef7f7-68a2-4ecd-9fef-045b426eb543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mentioned watching oz episode hoo...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visually stunnin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewer mentioned watching oz episode hoo...  positive\n",
       "1  wonderful little production filming technique ...  positive\n",
       "2  thought wonderful way spend time hot summer we...  positive\n",
       "3  basically family little boy jake think zombie ...  negative\n",
       "4  petter mattei love time money visually stunnin...  positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cd4988-8999-4b54-ab43-b6e3dfbb919d",
   "metadata": {},
   "source": [
    "## Splitting and Vectorizing the Dataset using TF-IDF Method\n",
    "- The dataset is divided into training and testing sets using `train_test_split()` to evaluate the model’s performance on dataset.\n",
    "- Text data is converted into numerical format using `TfidfVectorizer` so it can be processed by machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0235229b-535f-4133-8b7b-954917fafa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (50000, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,  # Only use the top 5000 words\n",
    "    ngram_range=(1, 2)  # Check single words & word pairs\n",
    ")\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(ds['review'])\n",
    "print(\"Shape:\", X_tfidf.shape)  # (50000 reviews, 5000 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4547e9f-409e-436d-8af4-99d2272627a4",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "- A machine learning model (Logistic Regression) is trained on the training data to learn how to classify sentiments.\n",
    "- The trained model is used to predict sentiments on the test dataset. Along with predictions, the model's **accuracy score** is calculated to measure how well it classifies the sentiments. Accuracy shows the percentage of correct predictions made by the model on the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbba7e94-13d4-4d8f-bb3c-365c94a78efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data\n",
    "y = ds['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2)\n",
    "\n",
    "# Train and test\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c955ff2-1f86-4418-83d7-5e59d5274d0f",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "The model's performance is evaluated using the following metrics:\n",
    "\n",
    "- **Precision**: Measures how many of the predicted positive sentiments are actually positive.  \n",
    "  *High precision = low false positives.*\n",
    "\n",
    "- **Recall**: Measures how many of the actual positive sentiments were correctly predicted.  \n",
    "  *High recall = low false negatives.*\n",
    "\n",
    "- **F1-Score**: The harmonic mean of precision and recall.  \n",
    "  *Useful when you need a balance between precision and recall, especially with imbalanced datasets.*\n",
    "\n",
    "These metrics provide a deeper insight into the model's performance beyond simple accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "623b7d1d-926f-4e40-a383-093caf54ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)  # Predicted sentiments (0 or 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc21791f-a92a-434d-88e1-906184a63980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88      4962\n",
      "           1       0.88      0.89      0.89      5038\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1856ae-6a80-416a-a034-a7e36d0fc840",
   "metadata": {},
   "source": [
    "## Summary and Insights\n",
    "\n",
    "In this project, we developed a **sentiment analysis model** to classify text data as either positive (1) or negative (0). The workflow included cleaning and preprocessing the text, transforming it into numerical features using TF-IDF, training a machine learning model, and evaluating its performance.\n",
    "\n",
    "### 📌 Final Results:\n",
    "- **Accuracy Score:** The model achieved an accuracy of approximately **88.5%** on the test set.\n",
    "- **Evaluation Metrics:**\n",
    "  - **Negative (0):**\n",
    "    - Precision: **0.89**\n",
    "    - Recall: **0.88**\n",
    "    - F1-Score: **0.88**\n",
    "    - Support: **4962 samples**\n",
    "  - **Positive (1):**\n",
    "    - Precision: **0.88**\n",
    "    - Recall: **0.89**\n",
    "    - F1-Score: **0.89**\n",
    "    - Support: **5038 samples**\n",
    "\n",
    "### 🔍 Key Insights:\n",
    "- The model demonstrated **balanced performance** across both positive and negative classes.\n",
    "- The **F1-scores for both classes (~0.88–0.89)** indicate a strong and consistent performance in correctly identifying sentiments.\n",
    "- **High precision and recall values** show that the model is effective in minimizing both false positives and false negatives.\n",
    "- **Text preprocessing** (e.g., lowercasing, lemmatization, stopword removal) and **TF-IDF vectorization** played a critical role in enhancing model quality.\n",
    "\n",
    "The model is well-suited for real-world applications in sentiment classification, providing reliable results across large-scale datasets.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
